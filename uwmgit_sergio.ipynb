{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "import efficientnet_pytorch\n",
    "#print(\"EfficientNet-PyTorch version:\", efficientnet_pytorch.__version__)\n",
    "import timm\n",
    "import mmcv\n",
    "sys.path.append('models/pytorch-image-models')\n",
    "#sys.path.append('models/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "#sys.path.append(\"../input/segmentation-models-pytorch/segmentation_models.pytorch-0.2.1\")\n",
    "#sys.path.append(\"../input/pretrainedmodels/pretrainedmodels-0.7.4\")\n",
    "#sys.path.append(\"models/EfficientNet-PyTorch\")\n",
    "\n",
    "#!pip install ../input/mmdetection/addict-2.4.0-py3-none-any.whl > /dev/null\n",
    "#!pip install ../input/mmdetection/yapf-0.31.0-py2.py3-none-any.whl > /dev/null\n",
    "#!pip install ../input/mmdetection/terminaltables-3.1.0-py3-none-any.whl > /dev/null\n",
    "#!pip install ../input/mmdetection/einops* > /dev/null\n",
    "#!pip install ../input/mmdetection/mmcv_full-1.3.17-cp37-cp37m-linux_x86_64.whl > /dev/null\n",
    "\n",
    "#subprocess.run([\"pip\", \"install\", \"../input/mmdetection/addict-2.4.0-py3-none-any.whl\"])\n",
    "#subprocess.run([\"pip\", \"install\", \"../input/mmdetection/yapf-0.31.0-py2.py3-none-any.whl\"])\n",
    "#subprocess.run([\"pip\", \"install\", \"../input/mmdetection/terminaltables-3.1.0-py3-none-any.whl\"])\n",
    "#subprocess.run([\"pip\", \"install\", \"../input/mmdetection/einops*\"])\n",
    "#subprocess.run([\"pip\", \"install\", \"../input/mmdetection/mmcv_full-1.3.17-cp37-cp37m-linux_x86_64.whl\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Install mmsegmentation \n",
    "\n",
    "This is from my own [mmseg github repo](https://github.com/CarnoZhao/Kaggle-UWMGIT) (leave a star if you like it!)\n",
    "\n",
    "I have integrated `segmentation_models_pytorch` in this version of `mmsegmentation`. Although `segmentation_models_pytorch`'s simple Unet performs better than some models of `mmsegmentation`, anyway, `mmsegmentation` is still a good library for segmentation task when you want to compare various models in a unified training pipeline.\n",
    "\n",
    "I only hard-coded `smp.Unet` in `./mmseg/models/segmentors/smp_models.py`. You can add more `smp` models in it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/CarnoZhao/Kaggle-UWMGIT && cd Kaggle-UWMGIT && pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Read csv and extract meta info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>patient</th>\n",
       "      <th>days</th>\n",
       "      <th>image_files</th>\n",
       "      <th>spacing_x</th>\n",
       "      <th>spacing_y</th>\n",
       "      <th>size_x</th>\n",
       "      <th>size_y</th>\n",
       "      <th>slice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case11_day0_slice_0001</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case11</td>\n",
       "      <td>case11_day0</td>\n",
       "      <td>images/train\\case11\\case11_day0\\scans\\slice_00...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>360</td>\n",
       "      <td>310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case11_day0_slice_0001</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case11</td>\n",
       "      <td>case11_day0</td>\n",
       "      <td>images/train\\case11\\case11_day0\\scans\\slice_00...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>360</td>\n",
       "      <td>310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case11_day0_slice_0001</td>\n",
       "      <td>stomach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case11</td>\n",
       "      <td>case11_day0</td>\n",
       "      <td>images/train\\case11\\case11_day0\\scans\\slice_00...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>360</td>\n",
       "      <td>310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case11_day0_slice_0002</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case11</td>\n",
       "      <td>case11_day0</td>\n",
       "      <td>images/train\\case11\\case11_day0\\scans\\slice_00...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>360</td>\n",
       "      <td>310</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case11_day0_slice_0002</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case11</td>\n",
       "      <td>case11_day0</td>\n",
       "      <td>images/train\\case11\\case11_day0\\scans\\slice_00...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>360</td>\n",
       "      <td>310</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7339</th>\n",
       "      <td>case9_day22_slice_0143</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case9</td>\n",
       "      <td>case9_day22</td>\n",
       "      <td>images/train\\case9\\case9_day22\\scans\\slice_014...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>360</td>\n",
       "      <td>310</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7340</th>\n",
       "      <td>case9_day22_slice_0143</td>\n",
       "      <td>stomach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case9</td>\n",
       "      <td>case9_day22</td>\n",
       "      <td>images/train\\case9\\case9_day22\\scans\\slice_014...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>360</td>\n",
       "      <td>310</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7341</th>\n",
       "      <td>case9_day22_slice_0144</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case9</td>\n",
       "      <td>case9_day22</td>\n",
       "      <td>images/train\\case9\\case9_day22\\scans\\slice_014...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>360</td>\n",
       "      <td>310</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7342</th>\n",
       "      <td>case9_day22_slice_0144</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case9</td>\n",
       "      <td>case9_day22</td>\n",
       "      <td>images/train\\case9\\case9_day22\\scans\\slice_014...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>360</td>\n",
       "      <td>310</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7343</th>\n",
       "      <td>case9_day22_slice_0144</td>\n",
       "      <td>stomach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case9</td>\n",
       "      <td>case9_day22</td>\n",
       "      <td>images/train\\case9\\case9_day22\\scans\\slice_014...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>360</td>\n",
       "      <td>310</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7344 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id        class segmentation patient         days  \\\n",
       "0     case11_day0_slice_0001  large_bowel          NaN  case11  case11_day0   \n",
       "1     case11_day0_slice_0001  small_bowel          NaN  case11  case11_day0   \n",
       "2     case11_day0_slice_0001      stomach          NaN  case11  case11_day0   \n",
       "3     case11_day0_slice_0002  large_bowel          NaN  case11  case11_day0   \n",
       "4     case11_day0_slice_0002  small_bowel          NaN  case11  case11_day0   \n",
       "...                      ...          ...          ...     ...          ...   \n",
       "7339  case9_day22_slice_0143  small_bowel          NaN   case9  case9_day22   \n",
       "7340  case9_day22_slice_0143      stomach          NaN   case9  case9_day22   \n",
       "7341  case9_day22_slice_0144  large_bowel          NaN   case9  case9_day22   \n",
       "7342  case9_day22_slice_0144  small_bowel          NaN   case9  case9_day22   \n",
       "7343  case9_day22_slice_0144      stomach          NaN   case9  case9_day22   \n",
       "\n",
       "                                            image_files  spacing_x  spacing_y  \\\n",
       "0     images/train\\case11\\case11_day0\\scans\\slice_00...        1.5        1.5   \n",
       "1     images/train\\case11\\case11_day0\\scans\\slice_00...        1.5        1.5   \n",
       "2     images/train\\case11\\case11_day0\\scans\\slice_00...        1.5        1.5   \n",
       "3     images/train\\case11\\case11_day0\\scans\\slice_00...        1.5        1.5   \n",
       "4     images/train\\case11\\case11_day0\\scans\\slice_00...        1.5        1.5   \n",
       "...                                                 ...        ...        ...   \n",
       "7339  images/train\\case9\\case9_day22\\scans\\slice_014...        1.5        1.5   \n",
       "7340  images/train\\case9\\case9_day22\\scans\\slice_014...        1.5        1.5   \n",
       "7341  images/train\\case9\\case9_day22\\scans\\slice_014...        1.5        1.5   \n",
       "7342  images/train\\case9\\case9_day22\\scans\\slice_014...        1.5        1.5   \n",
       "7343  images/train\\case9\\case9_day22\\scans\\slice_014...        1.5        1.5   \n",
       "\n",
       "      size_x  size_y  slice  \n",
       "0        360     310      1  \n",
       "1        360     310      1  \n",
       "2        360     310      1  \n",
       "3        360     310      2  \n",
       "4        360     310      2  \n",
       "...      ...     ...    ...  \n",
       "7339     360     310    143  \n",
       "7340     360     310    143  \n",
       "7341     360     310    144  \n",
       "7342     360     310    144  \n",
       "7343     360     310    144  \n",
       "\n",
       "[7344 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train_5cases_.csv\")\n",
    "df_train = df_train.sort_values([\"id\", \"class\"]).reset_index(drop = True)\n",
    "df_train[\"patient\"] = df_train.id.apply(lambda x: x.split(\"_\")[0])\n",
    "df_train[\"days\"] = df_train.id.apply(lambda x: \"_\".join(x.split(\"_\")[:2]))\n",
    "\n",
    "all_image_files = sorted(glob.glob(\"images/train/*/*/scans/*.png\"), key = lambda x: x.split(\"\\\\\")[2] + \"_\" + x.split(\"\\\\\")[4])\n",
    "size_x = [int(os.path.basename(_)[:-4].split(\"_\")[-4]) for _ in all_image_files]\n",
    "size_y = [int(os.path.basename(_)[:-4].split(\"_\")[-3]) for _ in all_image_files]\n",
    "spacing_x = [float(os.path.basename(_)[:-4].split(\"_\")[-2]) for _ in all_image_files]\n",
    "spacing_y = [float(os.path.basename(_)[:-4].split(\"_\")[-1]) for _ in all_image_files]\n",
    "df_train[\"image_files\"] = np.repeat(all_image_files, 3)\n",
    "df_train[\"spacing_x\"] = np.repeat(spacing_x, 3)\n",
    "df_train[\"spacing_y\"] = np.repeat(spacing_y, 3)\n",
    "df_train[\"size_x\"] = np.repeat(size_x, 3)\n",
    "df_train[\"size_y\"] = np.repeat(size_y, 3)\n",
    "df_train[\"slice\"] = np.repeat([int(os.path.basename(_)[:-4].split(\"_\")[-5]) for _ in all_image_files], 3)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Make mmseg-format data (2.5D by default)\n",
    "\n",
    "\n",
    "Here, I used 2.5d data with stride=2. Thanks this good trick from [https://www.kaggle.com/code/awsaf49/uwmgi-2-5d-stride-2-data](https://www.kaggle.com/code/awsaf49/uwmgi-2-5d-stride-2-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ToDo** The code bellow could be implemented more efficiently by using the .apply() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2150602288e14f93b673c5e2507d96bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This function decodes the rle and turns it to a matrix with 0 (background) and 1 (object)\n",
    "def rle_decode(mask_rle, shape):\n",
    "    s = np.array(mask_rle.split(), dtype=int)\n",
    "    starts, lengths = s[0::2] - 1, s[1::2]\n",
    "    ends = starts + lengths\n",
    "    h, w = shape\n",
    "    img = np.zeros((h * w,), dtype = np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo : hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "# This for loop takes out from the original dataframe chucks (called \"group\") curresponding to the same category \"days\" (keys).\n",
    "# Each row of the sub dataframe \"group\" includes all the images associated with a patient and a day of imaging\n",
    "#!mkdir -p .\\mmseg_train\\{images,labels,splits}\n",
    "# Create directories\n",
    "directories = ['./mmseg_train/images', './mmseg_train/labels', './mmseg_train/splits']\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "for day, group in tqdm(df_train.groupby(\"days\")):\n",
    "    patient = group.patient.iloc[0] #e.g. day101\n",
    "    imgs = []\n",
    "    msks = []\n",
    "    file_names = []\n",
    "    for file_name in group.image_files.unique(): # iterates over all the images of a single day (all images in the folder)\n",
    "        img = cv2.imread(file_name, cv2.IMREAD_ANYDEPTH) # reads the image\n",
    "        segms = group.loc[group.image_files == file_name] # takes all the segments included in that image (dataframe?)\n",
    "        masks = {}\n",
    "        # This for loop creates a dictionary of three masks (with 0s and 1s). If a slice is not label with an organ then the mask takes 0s\n",
    "        for segm, label in zip(segms.segmentation, segms[\"class\"]):\n",
    "            if not pd.isna(segm):\n",
    "                mask = rle_decode(segm, img.shape[:2])\n",
    "                masks[label] = mask\n",
    "            else:\n",
    "                masks[label] = np.zeros(img.shape[:2], dtype = np.uint8)\n",
    "        # Creates a three-dimsensional np.array\n",
    "        masks = np.stack([masks[k] for k in sorted(masks)], -1)\n",
    "        imgs.append(img) # A list? of 2D gray-scale images (as np.array) of shape (img.shape) \n",
    "        msks.append(masks) # A list? of 3D binary masks (as np.array) of shape (img.shape).Each mask includes three channels, one channel per organ\n",
    "    \n",
    "    # Creates a new array associated with the bias\n",
    "    # Specify the directory paths\n",
    "    images_dir = \"./mmseg_train/images\"\n",
    "    labels_dir = \"./mmseg_train/labels\"\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "    imgs = np.stack(imgs, 0)\n",
    "    msks = np.stack(msks, 0)\n",
    "    for i in range(msks.shape[0]):\n",
    "        img = imgs[[max(0, i - 2), i, min(imgs.shape[0] - 1, i + 2)]].transpose(1,2,0) # 2.5d data\n",
    "        msk = msks[i]\n",
    "        new_file_name = f\"{day}_{i}.png\"\n",
    "        # Write images\n",
    "        cv2.imwrite(os.path.join(images_dir, new_file_name), img)\n",
    "        cv2.imwrite(os.path.join(labels_dir, new_file_name), msk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Make fold splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_files = glob.glob(\"./mmseg_train/images/*\")\n",
    "patients = [os.path.basename(_).split(\"_\")[0] for _ in all_image_files]\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "split = list(GroupKFold(5).split(patients, groups = patients))\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(split):\n",
    "    with open(f\"./mmseg_train/splits/fold_{fold}.txt\", \"w\") as f:\n",
    "        for idx in train_idx:\n",
    "            f.write(os.path.basename(all_image_files[idx])[:-4] + \"\\n\")\n",
    "    with open(f\"./mmseg_train/splits/holdout_{fold}.txt\", \"w\") as f:\n",
    "        for idx in valid_idx:\n",
    "            f.write(os.path.basename(all_image_files[idx])[:-4] + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training\n",
    "\n",
    "## 4.1 Make config\n",
    "\n",
    "This is only **a simple baseline**, you can change anything in it\n",
    "\n",
    "From my own experiment, when using larger backbone, larger image size and more augs, the public score will be easily exceed 0.865.\n",
    "\n",
    "Here, I only train for 1k iters. **More iters are required to get a valid score**.\n",
    "\n",
    "I have made a single model submission scored 0.878 using this training pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "\n",
    "#cat <<EOT >> ./Kaggle-UWMGIT/config.py\n",
    "num_classes = 3\n",
    "\n",
    "# model settings\n",
    "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
    "loss = [\n",
    "    dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
    "]\n",
    "model = dict(\n",
    "    type='SMPUnet',\n",
    "    backbone=dict(\n",
    "        type='timm-efficientnet-b0',\n",
    "        pretrained=\"imagenet\"\n",
    "    ),\n",
    "    decode_head=dict(\n",
    "        num_classes=num_classes,\n",
    "        align_corners=False,\n",
    "        loss_decode=loss\n",
    "    ),\n",
    "    # model training and testing settings\n",
    "    train_cfg=dict(),\n",
    "    test_cfg=dict(mode=\"whole\", multi_label=True))\n",
    "\n",
    "# dataset settings\n",
    "dataset_type = 'CustomDataset'\n",
    "data_root = '../mmseg_train/'\n",
    "classes = ['large_bowel', 'small_bowel', 'stomach']\n",
    "palette = [[0,0,0], [128,128,128], [255,255,255]]\n",
    "img_norm_cfg = dict(mean=[0,0,0], std=[1,1,1], to_rgb=True)\n",
    "size = 256\n",
    "albu_train_transforms = [\n",
    "    dict(type='RandomBrightnessContrast', p=0.5),\n",
    "]\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile', to_float32=True, color_type='unchanged', max_value='max'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(size, size), keep_ratio=True),\n",
    "    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
    "    dict(type='Albu', transforms=albu_train_transforms),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='Pad', size=(size, size), pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile', to_float32=True, color_type='unchanged', max_value='max'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(size, size),\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **img_norm_cfg),\n",
    "            dict(type='Pad', size=(size, size), pad_val=0, seg_pad_val=255),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "data = dict(\n",
    "    samples_per_gpu=8,\n",
    "    workers_per_gpu=4,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        multi_label=True,\n",
    "        data_root=data_root,\n",
    "        img_dir='images',\n",
    "        ann_dir='labels',\n",
    "        img_suffix=\".png\",\n",
    "        seg_map_suffix='.png',\n",
    "        split=\"splits/fold_0.txt\",\n",
    "        classes=classes,\n",
    "        palette=palette,\n",
    "        pipeline=train_pipeline),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        multi_label=True,\n",
    "        data_root=data_root,\n",
    "        img_dir='images',\n",
    "        ann_dir='labels',\n",
    "        img_suffix=\".png\",\n",
    "        seg_map_suffix='.png',\n",
    "        split=\"splits/holdout_0.txt\",\n",
    "        classes=classes,\n",
    "        palette=palette,\n",
    "        pipeline=test_pipeline),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        multi_label=True,\n",
    "        data_root=data_root,\n",
    "        test_mode=True,\n",
    "        img_dir='test/images',\n",
    "        ann_dir='test/labels',\n",
    "        img_suffix=\".jpg\",\n",
    "        seg_map_suffix='.png',\n",
    "        classes=classes,\n",
    "        palette=palette,\n",
    "        pipeline=test_pipeline))\n",
    "\n",
    "# yapf:disable\n",
    "log_config = dict(\n",
    "    interval=50,\n",
    "    hooks=[\n",
    "        dict(type='CustomizedTextLoggerHook', by_epoch=False),\n",
    "    ])\n",
    "# yapf:enable\n",
    "dist_params = dict(backend='nccl')\n",
    "log_level = 'INFO'\n",
    "load_from = None\n",
    "resume_from = None\n",
    "workflow = [('train', 1)]\n",
    "cudnn_benchmark = True\n",
    "\n",
    "total_iters = 1\n",
    "# optimizer\n",
    "optimizer = dict(type='AdamW', lr=1e-3, betas=(0.9, 0.999), weight_decay=0.05)\n",
    "optimizer_config = dict(type='Fp16OptimizerHook', loss_scale='dynamic')\n",
    "# learning policy\n",
    "lr_config = dict(policy='poly',\n",
    "                 warmup='linear',\n",
    "                 warmup_iters=500,\n",
    "                 warmup_ratio=1e-6,\n",
    "                 power=1.0, min_lr=0.0, by_epoch=False)\n",
    "# runtime settings\n",
    "find_unused_parameters=True\n",
    "runner = dict(type='IterBasedRunner', max_iters=int(total_iters * 1000))\n",
    "checkpoint_config = dict(by_epoch=False, interval=int(total_iters * 1000), save_optimizer=False)\n",
    "evaluation = dict(by_epoch=False, interval=min(5000, int(total_iters * 1000)), metric=['imDice', 'mDice'], pre_eval=True)\n",
    "fp16 = dict()\n",
    "\n",
    "work_dir = f'./work_dirs/tract/baseline'\n",
    "#EOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Let's start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['cp', 'r', '../input/timm-pytorch-image-models/pytorch-image-models-master ./ && cd pytorch-image-models-master  && pip install -e .'], returncode=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reinstall for inner bash usage\n",
    "#!cp -r ../input/segmentation-models-pytorch/segmentation_models.pytorch-0.2.1 ./ && cd segmentation_models.pytorch-0.2.1  && pip install -e .\n",
    "#!cp -r ../input/timm-pytorch-image-models/pytorch-image-models-master ./ && cd pytorch-image-models-master  && pip install -e .\n",
    "#!cp -r model/tipytorch-image-models/pytorch-image-models-master ./ && cd pytorch-image-models-master  && pip install -e .\n",
    "\n",
    "#!copy /Y ..\\input\\segmentation-models-pytorch\\segmentation_models.pytorch-0.2.1 .\\ && cd segmentation_models.pytorch-0.2.1 && pip install -e .\n",
    "#!copy /Y ..\\input\\timm-pytorch-image-models\\pytorch-image-models-master .\\ && cd pytorch-image-models-master && pip install -e .\n",
    "#subprocess.run([\"cp\",\"r\",\"../input/segmentation-models-pytorch/segmentation_models.pytorch-0.2.1 ./ && cd segmentation_models.pytorch-0.2.1  && pip install -e .\"])\n",
    "#subprocess.run([\"cp\",\"r\",\"../input/timm-pytorch-image-models/pytorch-image-models-master ./ && cd pytorch-image-models-master  && pip install -e .\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Traceback (most recent call last):\n",
      "  File \"D:\\Courses\\2024-02-12_Data_Science_Spice\\dats-data\\Kaggle-UWMGIT\\tools\\train.py\", line 16, in <module>\n",
      "    from mmseg.apis import init_random_seed, set_random_seed, train_segmentor\n",
      "  File \"C:\\Users\\ssre_\\.pyenv\\pyenv-win\\versions\\3.11.6\\Lib\\site-packages\\mmseg\\apis\\__init__.py\", line 2, in <module>\n",
      "    from .inference import inference_model, init_model, show_result_pyplot\n",
      "  File \"C:\\Users\\ssre_\\.pyenv\\pyenv-win\\versions\\3.11.6\\Lib\\site-packages\\mmseg\\apis\\inference.py\", line 14, in <module>\n",
      "    from mmseg.models import BaseSegmentor\n",
      "  File \"C:\\Users\\ssre_\\.pyenv\\pyenv-win\\versions\\3.11.6\\Lib\\site-packages\\mmseg\\models\\__init__.py\", line 3, in <module>\n",
      "    from .backbones import *  # noqa: F401,F403\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ssre_\\.pyenv\\pyenv-win\\versions\\3.11.6\\Lib\\site-packages\\mmseg\\models\\backbones\\__init__.py\", line 2, in <module>\n",
      "    from .beit import BEiT\n",
      "  File \"C:\\Users\\ssre_\\.pyenv\\pyenv-win\\versions\\3.11.6\\Lib\\site-packages\\mmseg\\models\\backbones\\beit.py\", line 19, in <module>\n",
      "    from ..utils import PatchEmbed\n",
      "  File \"C:\\Users\\ssre_\\.pyenv\\pyenv-win\\versions\\3.11.6\\Lib\\site-packages\\mmseg\\models\\utils\\__init__.py\", line 2, in <module>\n",
      "    from .basic_block import BasicBlock, Bottleneck\n",
      "  File \"C:\\Users\\ssre_\\.pyenv\\pyenv-win\\versions\\3.11.6\\Lib\\site-packages\\mmseg\\models\\utils\\basic_block.py\", line 10, in <module>\n",
      "    from mmseg.utils import OptConfigType\n",
      "  File \"C:\\Users\\ssre_\\.pyenv\\pyenv-win\\versions\\3.11.6\\Lib\\site-packages\\mmseg\\utils\\__init__.py\", line 24, in <module>\n",
      "    from .mask_classification import MatchMasks, seg_data_to_instance_data\n",
      "  File \"C:\\Users\\ssre_\\.pyenv\\pyenv-win\\versions\\3.11.6\\Lib\\site-packages\\mmseg\\utils\\mask_classification.py\", line 5, in <module>\n",
      "    from mmcv.ops import point_sample\n",
      "  File \"C:\\Users\\ssre_\\.pyenv\\pyenv-win\\versions\\3.11.6\\Lib\\site-packages\\mmcv\\ops\\__init__.py\", line 2, in <module>\n",
      "    from .active_rotated_filter import active_rotated_filter\n",
      "  File \"C:\\Users\\ssre_\\.pyenv\\pyenv-win\\versions\\3.11.6\\Lib\\site-packages\\mmcv\\ops\\active_rotated_filter.py\", line 10, in <module>\n",
      "    ext_module = ext_loader.load_ext(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ssre_\\.pyenv\\pyenv-win\\versions\\3.11.6\\Lib\\site-packages\\mmcv\\utils\\ext_loader.py\", line 13, in load_ext\n",
      "    ext = importlib.import_module('mmcv.' + name)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ssre_\\.pyenv\\pyenv-win\\versions\\3.11.6\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ModuleNotFoundError: No module named 'mmcv._ext'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%bash\n",
    "\n",
    "#cd Kaggle-UWMGIT\n",
    "\n",
    "#python ./tools/train.py ./config.py --gpu-ids 0\n",
    "#!python Kaggle-UWMGIT/tools/train.py Kaggle-UWMGIT/config.py --gpu-ids 0\n",
    "#subprocess.run([\"python\",\"Kaggle-UWMGIT/tools/train.py\",\"Kaggle-UWMGIT/config.py\",\"--gpu-ids 0\"])\n",
    "\n",
    "command = [\"python\", \"Kaggle-UWMGIT/tools/train.py\", \"Kaggle-UWMGIT/config.py\", \"--gpu-ids\", \"0\"]\n",
    "\n",
    "# Execute the command using subprocess.run()\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "# Check the result\n",
    "if result.returncode != 0:\n",
    "    print(\"Error:\", result.stderr)\n",
    "else:\n",
    "    print(\"Command executed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Inferencing\n",
    "\n",
    "## 5.1 Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-09T09:15:54.574832Z",
     "iopub.status.busy": "2022-05-09T09:15:54.574088Z",
     "iopub.status.idle": "2022-05-09T09:16:15.155125Z",
     "shell.execute_reply": "2022-05-09T09:16:15.154002Z",
     "shell.execute_reply.started": "2022-05-09T09:15:54.574788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ./Kaggle-UWMGIT/work_dirs/tract/baseline/latest.pth\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('./Kaggle-UWMGIT')\n",
    "from mmseg.apis import init_segmentor, inference_segmentor\n",
    "from mmcv.utils import config\n",
    "\n",
    "cfgs = [\n",
    "    \"./Kaggle-UWMGIT/work_dirs/tract/baseline/config.py\",\n",
    "]\n",
    "\n",
    "ckpts = [\n",
    "    \"./Kaggle-UWMGIT/work_dirs/tract/baseline/latest.pth\",\n",
    "]\n",
    "\n",
    "models = []\n",
    "for cfg, ckpt in zip(cfgs, ckpts):\n",
    "    cfg = config.Config.fromfile(cfg)\n",
    "    cfg.model.backbone.pretrained = None\n",
    "    cfg.model.test_cfg.logits = True\n",
    "    cfg.data.test.pipeline[1].transforms.insert(2, dict(type=\"Normalize\", mean=[0,0,0], std=[1,1,1], to_rgb=False))\n",
    "\n",
    "    model = init_segmentor(cfg, ckpt)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Make test submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-09T09:16:22.372768Z",
     "iopub.status.busy": "2022-05-09T09:16:22.372231Z",
     "iopub.status.idle": "2022-05-09T09:16:27.031128Z",
     "shell.execute_reply": "2022-05-09T09:16:27.030078Z",
     "shell.execute_reply.started": "2022-05-09T09:16:22.372730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predicted</th>\n",
       "      <th>file_name</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td></td>\n",
       "      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n",
       "      <td>case123_day20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td></td>\n",
       "      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n",
       "      <td>case123_day20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>stomach</td>\n",
       "      <td></td>\n",
       "      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n",
       "      <td>case123_day20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td></td>\n",
       "      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n",
       "      <td>case123_day20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td></td>\n",
       "      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n",
       "      <td>case123_day20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>case123_day20_slice_0099</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td></td>\n",
       "      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n",
       "      <td>case123_day20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>case123_day20_slice_0099</td>\n",
       "      <td>stomach</td>\n",
       "      <td></td>\n",
       "      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n",
       "      <td>case123_day20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>case123_day20_slice_0100</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td></td>\n",
       "      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n",
       "      <td>case123_day20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>case123_day20_slice_0100</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td></td>\n",
       "      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n",
       "      <td>case123_day20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>case123_day20_slice_0100</td>\n",
       "      <td>stomach</td>\n",
       "      <td></td>\n",
       "      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n",
       "      <td>case123_day20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id        class predicted  \\\n",
       "0    case123_day20_slice_0001  large_bowel             \n",
       "1    case123_day20_slice_0001  small_bowel             \n",
       "2    case123_day20_slice_0001      stomach             \n",
       "3    case123_day20_slice_0002  large_bowel             \n",
       "4    case123_day20_slice_0002  small_bowel             \n",
       "..                        ...          ...       ...   \n",
       "295  case123_day20_slice_0099  small_bowel             \n",
       "296  case123_day20_slice_0099      stomach             \n",
       "297  case123_day20_slice_0100  large_bowel             \n",
       "298  case123_day20_slice_0100  small_bowel             \n",
       "299  case123_day20_slice_0100      stomach             \n",
       "\n",
       "                                             file_name           days  \n",
       "0    ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n",
       "1    ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n",
       "2    ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n",
       "3    ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n",
       "4    ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n",
       "..                                                 ...            ...  \n",
       "295  ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n",
       "296  ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n",
       "297  ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n",
       "298  ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n",
       "299  ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.ndimage import binary_closing, binary_opening, measurements\n",
    "\n",
    "def rle_encode(img):\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "classes = ['large_bowel', 'small_bowel', 'stomach']\n",
    "data_dir = \"../input/uw-madison-gi-tract-image-segmentation/\"\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "sub = pd.read_csv(os.path.join(data_dir, \"sample_submission.csv\"))\n",
    "test_images = glob.glob(os.path.join(test_dir, \"**\", \"*.png\"), recursive = True)\n",
    "\n",
    "if len(test_images) == 0:\n",
    "    test_dir = os.path.join(data_dir, \"train\")\n",
    "    sub = pd.read_csv(os.path.join(data_dir, \"train.csv\"))[[\"id\", \"class\"]].iloc[:100 * 3]\n",
    "    sub[\"predicted\"] = \"\"\n",
    "    test_images = glob.glob(os.path.join(test_dir, \"**\", \"*.png\"), recursive = True)\n",
    "    \n",
    "id2img = {_.rsplit(\"/\", 4)[2] + \"_\" + \"_\".join(_.rsplit(\"/\", 4)[4].split(\"_\")[:2]): _ for _ in test_images}\n",
    "sub[\"file_name\"] = sub.id.map(id2img)\n",
    "sub[\"days\"] = sub.id.apply(lambda x: \"_\".join(x.split(\"_\")[:2]))\n",
    "fname2index = {f + c: i for f, c, i in zip(sub.file_name, sub[\"class\"], sub.index)}\n",
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Start Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-09T09:18:59.247667Z",
     "iopub.status.busy": "2022-05-09T09:18:59.247102Z",
     "iopub.status.idle": "2022-05-09T09:19:03.890284Z",
     "shell.execute_reply": "2022-05-09T09:19:03.889256Z",
     "shell.execute_reply.started": "2022-05-09T09:18:59.247630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45fb8b28f155414eb09d2d79d0da85c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subs = []\n",
    "for day, group in tqdm(sub.groupby(\"days\")):\n",
    "    imgs = []\n",
    "    for file_name in group.file_name.unique():\n",
    "        img = cv2.imread(file_name, cv2.IMREAD_ANYDEPTH)\n",
    "        old_size = img.shape[:2]\n",
    "        s = int(os.path.basename(file_name).split(\"_\")[1])\n",
    "        file_names = [file_name.replace(f\"slice_{s:04d}\", f\"slice_{s + i:04d}\") for i in range(-2, 3)]\n",
    "        file_names = [_ for _ in file_names if os.path.exists(_)]\n",
    "        imgs = [cv2.imread(file_names[0], cv2.IMREAD_ANYDEPTH)] + [img] + [cv2.imread(file_names[-1], cv2.IMREAD_ANYDEPTH)]\n",
    "        \n",
    "        new_img = np.stack(imgs, -1)\n",
    "        new_img = new_img.astype(np.float32) / new_img.max()\n",
    "\n",
    "        res = [inference_segmentor(model, new_img)[0] for model in models]\n",
    "        res = (sum(res) / len(res)).round().astype(np.uint8)\n",
    "        res = cv2.resize(res, old_size[::-1], interpolation = cv2.INTER_NEAREST)\n",
    "        for j in range(3):\n",
    "            rle = rle_encode(res[...,j])\n",
    "            index = fname2index[file_name + classes[j]]\n",
    "            sub.loc[index, \"predicted\"] = rle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Format submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-09T09:19:09.193998Z",
     "iopub.status.busy": "2022-05-09T09:19:09.193695Z",
     "iopub.status.idle": "2022-05-09T09:19:09.218688Z",
     "shell.execute_reply": "2022-05-09T09:19:09.217291Z",
     "shell.execute_reply.started": "2022-05-09T09:19:09.193967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>stomach</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>case123_day20_slice_0099</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>case123_day20_slice_0099</td>\n",
       "      <td>stomach</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>case123_day20_slice_0100</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>case123_day20_slice_0100</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>case123_day20_slice_0100</td>\n",
       "      <td>stomach</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id        class predicted\n",
       "0    case123_day20_slice_0001  large_bowel          \n",
       "1    case123_day20_slice_0001  small_bowel          \n",
       "2    case123_day20_slice_0001      stomach          \n",
       "3    case123_day20_slice_0002  large_bowel          \n",
       "4    case123_day20_slice_0002  small_bowel          \n",
       "..                        ...          ...       ...\n",
       "295  case123_day20_slice_0099  small_bowel          \n",
       "296  case123_day20_slice_0099      stomach          \n",
       "297  case123_day20_slice_0100  large_bowel          \n",
       "298  case123_day20_slice_0100  small_bowel          \n",
       "299  case123_day20_slice_0100      stomach          \n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = sub[[\"id\", \"class\", \"predicted\"]]\n",
    "sub.to_csv(\"submission.csv\", index = False)\n",
    "sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_common",
   "language": "python",
   "name": ".venv_common"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
